{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "743637a7",
   "metadata": {},
   "source": [
    "# Tracing and Quantization with PyTorch and Torchscript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb17efe",
   "metadata": {},
   "source": [
    "## [(PROTOTYPE) FX GRAPH MODE QUANTIZATION USER GUIDE](https://pytorch.org/tutorials/prototype/fx_graph_mode_quant_guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea477c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.9.0\n",
      "  Downloading https://download.pytorch.org/whl/rocm4.2/torch-1.9.0%2Brocm4.2-cp36-cp36m-linux_x86_64.whl (995.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 995.4 MB 69.6 MB/s eta 0:00:01     |█████████████████████▊          | 676.7 MB 54.0 MB/s eta 0:00:06     |██████████████████████████████▎ | 942.8 MB 21.5 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch==1.9.0) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch==1.9.0) (0.8)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 1.0.61 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Successfully installed torch-1.9.0+rocm4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir torch==1.9.0 -f https://download.pytorch.org/whl/torch_stable.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dee0a819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (4.7.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-1.8.0-py3-none-any.whl (237 kB)\n",
      "\u001b[K     |████████████████████████████████| 237 kB 21.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets) (0.8)\n",
      "Collecting tqdm<4.50.0,>=4.27\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp36-cp36m-manylinux2010_x86_64.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 60.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets) (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets) (0.0.8)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets) (0.3.3)\n",
      "Collecting pyarrow<4.0.0,>=1.0.0\n",
      "  Downloading pyarrow-3.0.0-cp36-cp36m-manylinux2014_x86_64.whl (20.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.7 MB 59.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets) (0.8.7)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->datasets) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: tqdm, xxhash, pyarrow, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.57.0\n",
      "    Uninstalling tqdm-4.57.0:\n",
      "      Successfully uninstalled tqdm-4.57.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 4.0.0\n",
      "    Uninstalling pyarrow-4.0.0:\n",
      "      Successfully uninstalled pyarrow-4.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 1.0.61 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Successfully installed datasets-1.8.0 pyarrow-3.0.0 tqdm-4.49.0 xxhash-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c18e4",
   "metadata": {},
   "source": [
    "## load a bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35eab6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a545b8a8d8041de8c34081181a9c7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e2141e5f0b48a6a218ce6f04a2fb89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cf10f641014f07bf7ffa2577762da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271095107ee14b07a5ebc0ccc17086ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3c14976a94434f9faae2ea0006b018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Build tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\", return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe23f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some example inputs\n",
    "sequence_0 = \"The company HuggingFace is based in New York City\"\n",
    "sequence_1 = \"Apples are especially bad for your health\"\n",
    "sequence_2 = \"HuggingFace's headquarters are situated in Manhattan\"\n",
    "\n",
    "max_length=128\n",
    "paraphrase = tokenizer.encode_plus(sequence_0, sequence_2, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "example_inputs_paraphrase = paraphrase['input_ids'], paraphrase['attention_mask'], paraphrase['token_type_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ec1937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model(**paraphrase)[0][0].argmax().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058d0f2",
   "metadata": {},
   "source": [
    "## eager quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d6114d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): DynamicQuantizedLinear(in_features=768, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "print(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ac169c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 433.328557\n",
      "Size (MB): 176.806533\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "print_size_of_model(model)\n",
    "print_size_of_model(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01054924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/ec2-user/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,load_metric\n",
    "import time\n",
    "\n",
    "task = \"mrpc\"\n",
    "split=\"validation\"\n",
    "all_datasets = load_dataset(\"glue\", task)\n",
    "metric = load_metric(\"glue\", task)\n",
    "dataset= all_datasets[split]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "max_length=64\n",
    "padding='max_length'\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    texts = (examples['sentence1'], examples['sentence2'])\n",
    "    result = tokenizer(*texts, padding=padding, max_length=max_length, truncation=True,return_tensors=\"pt\")\n",
    "    result[\"labels\"] = examples[\"label\"]\n",
    "    return result\n",
    "\n",
    "\n",
    "def do_test(raw_dataset,model,model_type,mode):\n",
    "    processed_dataset = raw_dataset.map(preprocess_function)\n",
    "    processed_dataset = processed_dataset.select(range(1000))\n",
    "    model_start = time.perf_counter()\n",
    "#     model_type = 'neuron' if isinstance(model, torch.jit.ScriptModule) else 'torch'\n",
    "    if mode == 'no_grad':\n",
    "        with torch.no_grad():\n",
    "            for step, batch in enumerate(processed_dataset):\n",
    "                input_ids = torch.tensor(batch['input_ids'])\n",
    "                attention_mask = torch.tensor(batch['attention_mask'])\n",
    "                token_type_ids = torch.tensor(batch['token_type_ids'])\n",
    "                outputs = model(*[input_ids,attention_mask,token_type_ids])\n",
    "                predictions = outputs[0][0].argmax().item()\n",
    "                metric.add_batch(predictions=[predictions],references=[batch[\"labels\"]])\n",
    "    else:\n",
    "        with torch.inference_mode():\n",
    "            for step, batch in enumerate(processed_dataset):\n",
    "                input_ids = torch.tensor(batch['input_ids'])\n",
    "                attention_mask = torch.tensor(batch['attention_mask'])\n",
    "                token_type_ids = torch.tensor(batch['token_type_ids'])\n",
    "                outputs = model(*[input_ids,attention_mask,token_type_ids])\n",
    "                predictions = outputs[0][0].argmax().item()\n",
    "                metric.add_batch(predictions=[predictions],references=[batch[\"labels\"]])\n",
    "        \n",
    "    eval_metric = metric.compute()\n",
    "    model_stop = time.perf_counter()\n",
    "    total_time = round(model_stop - model_start,4)*1000\n",
    "    average_time =  round(total_time/len(processed_dataset),4)\n",
    "    return {'model_type':model_type,\n",
    "            **eval_metric,\n",
    "            'total_time':f\"{total_time}ms\",\n",
    "            'average_time':f\"{average_time}ms\",\n",
    "            'max_length':max_length,\n",
    "            'samples': len(processed_dataset),\n",
    "            'task': task,\n",
    "            'mode':mode\n",
    "           }   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e41fbf",
   "metadata": {},
   "source": [
    "## Trace quantized model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b9cf031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_utils.py:1965: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  input_tensor.shape[chunk_dim] == tensor_shape for input_tensor in input_tensors\n"
     ]
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(quantized_model, example_inputs_paraphrase)\n",
    "torch.jit.save(traced_model, \"bert_traced_eager_quant.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c69af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_traced_quantized = torch.jit.load('bert_traced_eager_quant.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9629436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d4d8c785d445e38fb1933b0148e72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/408 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1986a9a0f4f74fb4bea4f9cef1d75c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/408 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecdc45ff3094360a.arrow\n",
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecdc45ff3094360a.arrow\n",
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecdc45ff3094360a.arrow\n",
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecdc45ff3094360a.arrow\n"
     ]
    }
   ],
   "source": [
    "# normal\n",
    "model_res_no_grad=do_test(dataset, model,'pytorch','no_grad')\n",
    "model_res_inference_mode=do_test(dataset, model,'pytorch','inference_mode')\n",
    "# quantized\n",
    "model_quantized_res_no_grad = do_test(dataset, quantized_model,'quantized','no_grad')\n",
    "model_quantized_res_inference_mode = do_test(dataset, quantized_model,'quantized','inference_mode')\n",
    "# quantized_traced \n",
    "model_traced_quantized_res_no_grad = do_test(dataset, model_traced_quantized,'traced_quantized','no_grad')\n",
    "model_traced_quantized_res_inference_mode = do_test(dataset, model_traced_quantized,'traced_quantized','inference_mode')\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([model_res_no_grad,model_res_inference_mode,model_quantized_res_no_grad,model_quantized_res_inference_mode,model_traced_quantized_res_no_grad,model_traced_quantized_res_inference_mode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2d9f65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>total_time</th>\n",
       "      <th>average_time</th>\n",
       "      <th>max_length</th>\n",
       "      <th>samples</th>\n",
       "      <th>task</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.899320</td>\n",
       "      <td>128947.20000000001ms</td>\n",
       "      <td>128.9472ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>no_grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.899320</td>\n",
       "      <td>127289.2ms</td>\n",
       "      <td>127.2892ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>inference_mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quantized</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>101038.5ms</td>\n",
       "      <td>101.0385ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>no_grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quantized</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>99298.1ms</td>\n",
       "      <td>99.2981ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>inference_mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>traced_quantized</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>87877.70000000001ms</td>\n",
       "      <td>87.8777ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>no_grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>traced_quantized</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>85958.0ms</td>\n",
       "      <td>85.958ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>inference_mode</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_type  accuracy        f1            total_time average_time  \\\n",
       "0           pytorch     0.852  0.899320  128947.20000000001ms   128.9472ms   \n",
       "1           pytorch     0.852  0.899320            127289.2ms   127.2892ms   \n",
       "2         quantized     0.833  0.888145            101038.5ms   101.0385ms   \n",
       "3         quantized     0.833  0.888145             99298.1ms    99.2981ms   \n",
       "4  traced_quantized     0.833  0.888145   87877.70000000001ms    87.8777ms   \n",
       "5  traced_quantized     0.833  0.888145             85958.0ms     85.958ms   \n",
       "\n",
       "   max_length  samples  task            mode  \n",
       "0          64     1000  mrpc         no_grad  \n",
       "1          64     1000  mrpc  inference_mode  \n",
       "2          64     1000  mrpc         no_grad  \n",
       "3          64     1000  mrpc  inference_mode  \n",
       "4          64     1000  mrpc         no_grad  \n",
       "5          64     1000  mrpc  inference_mode  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c46744fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>total_time</th>\n",
       "      <th>average_time</th>\n",
       "      <th>max_length</th>\n",
       "      <th>samples</th>\n",
       "      <th>task</th>\n",
       "      <th>mode</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.899320</td>\n",
       "      <td>128947.20000000001ms</td>\n",
       "      <td>128.9472ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>no_grad</td>\n",
       "      <td>1.0x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.899320</td>\n",
       "      <td>127289.2ms</td>\n",
       "      <td>127.2892ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>inference_mode</td>\n",
       "      <td>1.013x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quantized</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>101038.5ms</td>\n",
       "      <td>101.0385ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>no_grad</td>\n",
       "      <td>1.2762x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quantized</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>99298.1ms</td>\n",
       "      <td>99.2981ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>inference_mode</td>\n",
       "      <td>1.2986x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>traced_quantized</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>87877.70000000001ms</td>\n",
       "      <td>87.8777ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>no_grad</td>\n",
       "      <td>1.4673x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>traced_quantized</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>85958.0ms</td>\n",
       "      <td>85.958ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>inference_mode</td>\n",
       "      <td>1.5001x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_type  accuracy        f1            total_time average_time  \\\n",
       "0           pytorch     0.852  0.899320  128947.20000000001ms   128.9472ms   \n",
       "1           pytorch     0.852  0.899320            127289.2ms   127.2892ms   \n",
       "2         quantized     0.833  0.888145            101038.5ms   101.0385ms   \n",
       "3         quantized     0.833  0.888145             99298.1ms    99.2981ms   \n",
       "4  traced_quantized     0.833  0.888145   87877.70000000001ms    87.8777ms   \n",
       "5  traced_quantized     0.833  0.888145             85958.0ms     85.958ms   \n",
       "\n",
       "   max_length  samples  task            mode performance  \n",
       "0          64     1000  mrpc         no_grad        1.0x  \n",
       "1          64     1000  mrpc  inference_mode      1.013x  \n",
       "2          64     1000  mrpc         no_grad     1.2762x  \n",
       "3          64     1000  mrpc  inference_mode     1.2986x  \n",
       "4          64     1000  mrpc         no_grad     1.4673x  \n",
       "5          64     1000  mrpc  inference_mode     1.5001x  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['performance'] = df.apply(lambda x: str(round(float(df.query('model_type == \"pytorch\" & mode == \"no_grad\"')['average_time'][0].replace('ms',''))/float(x['average_time'].replace('ms','')),4))+\"x\",axis=1)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54c1f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pytorch_1_9_0_inference_mode_vs_no_grad_64_seq.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc732c9",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60523dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model_type</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>total_time</th>\n",
       "      <th>average_time</th>\n",
       "      <th>max_length</th>\n",
       "      <th>samples</th>\n",
       "      <th>task</th>\n",
       "      <th>mode</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>116347.0ms</td>\n",
       "      <td>232.694ms</td>\n",
       "      <td>128</td>\n",
       "      <td>500</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>no_grad</td>\n",
       "      <td>1.0x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>112168.40000000001ms</td>\n",
       "      <td>224.3368ms</td>\n",
       "      <td>128</td>\n",
       "      <td>500</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>inference_mode</td>\n",
       "      <td>1.0373x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>quantized</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.895805</td>\n",
       "      <td>95697.3ms</td>\n",
       "      <td>191.3946ms</td>\n",
       "      <td>128</td>\n",
       "      <td>500</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>no_grad</td>\n",
       "      <td>1.2158x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>quantized</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.895805</td>\n",
       "      <td>93191.40000000001ms</td>\n",
       "      <td>186.3828ms</td>\n",
       "      <td>128</td>\n",
       "      <td>500</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>inference_mode</td>\n",
       "      <td>1.2485x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>traced_quantized</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.895805</td>\n",
       "      <td>87867.5ms</td>\n",
       "      <td>175.735ms</td>\n",
       "      <td>128</td>\n",
       "      <td>500</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>no_grad</td>\n",
       "      <td>1.3241x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>traced_quantized</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.895805</td>\n",
       "      <td>86415.09999999999ms</td>\n",
       "      <td>172.8302ms</td>\n",
       "      <td>128</td>\n",
       "      <td>500</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>inference_mode</td>\n",
       "      <td>1.3464x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        model_type  accuracy        f1            total_time  \\\n",
       "0           0           pytorch     0.860  0.903846            116347.0ms   \n",
       "1           1           pytorch     0.860  0.903846  112168.40000000001ms   \n",
       "2           2         quantized     0.846  0.895805             95697.3ms   \n",
       "3           3         quantized     0.846  0.895805   93191.40000000001ms   \n",
       "4           4  traced_quantized     0.846  0.895805             87867.5ms   \n",
       "5           5  traced_quantized     0.846  0.895805   86415.09999999999ms   \n",
       "\n",
       "  average_time  max_length  samples  task            mode performance  \n",
       "0    232.694ms         128      500  mrpc         no_grad        1.0x  \n",
       "1   224.3368ms         128      500  mrpc  inference_mode     1.0373x  \n",
       "2   191.3946ms         128      500  mrpc         no_grad     1.2158x  \n",
       "3   186.3828ms         128      500  mrpc  inference_mode     1.2485x  \n",
       "4    175.735ms         128      500  mrpc         no_grad     1.3241x  \n",
       "5   172.8302ms         128      500  mrpc  inference_mode     1.3464x  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"pytorch_1_9_0_inference_mode_vs_no_grad_128_seq.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "176b0109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model_type</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>total_time</th>\n",
       "      <th>average_time</th>\n",
       "      <th>max_length</th>\n",
       "      <th>samples</th>\n",
       "      <th>task</th>\n",
       "      <th>mode</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.899320</td>\n",
       "      <td>128947.20000000001ms</td>\n",
       "      <td>128.9472ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>no_grad</td>\n",
       "      <td>1.0x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.899320</td>\n",
       "      <td>127289.2ms</td>\n",
       "      <td>127.2892ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>inference_mode</td>\n",
       "      <td>1.013x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>quantized</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>101038.5ms</td>\n",
       "      <td>101.0385ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>no_grad</td>\n",
       "      <td>1.2762x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>quantized</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>99298.1ms</td>\n",
       "      <td>99.2981ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>inference_mode</td>\n",
       "      <td>1.2986x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>traced_quantized</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>87877.70000000001ms</td>\n",
       "      <td>87.8777ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>no_grad</td>\n",
       "      <td>1.4673x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>traced_quantized</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>85958.0ms</td>\n",
       "      <td>85.958ms</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>inference_mode</td>\n",
       "      <td>1.5001x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        model_type  accuracy        f1            total_time  \\\n",
       "0           0           pytorch     0.852  0.899320  128947.20000000001ms   \n",
       "1           1           pytorch     0.852  0.899320            127289.2ms   \n",
       "2           2         quantized     0.833  0.888145            101038.5ms   \n",
       "3           3         quantized     0.833  0.888145             99298.1ms   \n",
       "4           4  traced_quantized     0.833  0.888145   87877.70000000001ms   \n",
       "5           5  traced_quantized     0.833  0.888145             85958.0ms   \n",
       "\n",
       "  average_time  max_length  samples  task            mode performance  \n",
       "0   128.9472ms          64     1000  mrpc         no_grad        1.0x  \n",
       "1   127.2892ms          64     1000  mrpc  inference_mode      1.013x  \n",
       "2   101.0385ms          64     1000  mrpc         no_grad     1.2762x  \n",
       "3    99.2981ms          64     1000  mrpc  inference_mode     1.2986x  \n",
       "4    87.8777ms          64     1000  mrpc         no_grad     1.4673x  \n",
       "5     85.958ms          64     1000  mrpc  inference_mode     1.5001x  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"pytorch_1_9_0_inference_mode_vs_no_grad_64_seq.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b6a233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
